##############################################################################
#
#   Kennedy Institute of Rheumatology
#
#   $Id$
#
#   Copyright (C) 2018 Stephen Sansom
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
###############################################################################

"""===========================
Pipeline Seurat
===========================

:Author: Sansom lab
:Release: $Id$
:Date: |today|
:Tags: Python

Overview
========

This pipeline wraps the Satija lab's Seurat (http://satijalab.org/seurat/)
package using a set of Rscripts.

For key parameters a range of choices can be specified. The pipeline will
generate one report for each parameter combination, dispatching analyses
from multiple samples in parallel for execution on a HPC cluster.

The pipeline also performs cluster geneset enrichment analysis using the
"gsfisher" R package (http://github/sansomlab/gsfisher).

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_seurat.py config


Input files
-----------

The pipeline can be run either:
(A) starting from a suitable count matrix and metadata file (such as
the output of pipeline_cellranger.py) or
(B) starting from a saved seurat object. This is useful for analysing
an object to which reduced dimensions from another method (e.g. zinbwave)
have been added.
Optionally, velocity plots can be included, which require the optional
run of the tool dropEst within the cellranger pipeline (see below).

(A) Starting from a processed tenx count matrix (and a metadata.tsv file).

Typically involves linking "dataset.dir" subfolders from a
pipeline_cellranger.py run.

A folder containing the expression matrix (market exchange format)
and metadata.tsv file should be linked into a "data.dir" subfolder.
The folder names must end with ".dir".

e.g.

$ ls data.dir
agg.dir               d1_control_mono.dir  d2_butyrate_mono.dir
d1_butyrate_mono.dir  d1_tmp195_mono.dir   d2_control_mono.dir

$ ls data.dir/agg.dir/
barcodes.tsv  genes.tsv  matrix.mtx  metadata.tsv

(B) Starting from a saved seurat object.

The pipeline can run downstream analysis on a saved seurat object (RDS
format) on which qc, data normalisation, selection of variable genes and
dimension reduction has been performed.

Each sample should be placed (or linked) as a "begin.rds" file in a directory
ending with ".seurat.dir", e.g.

wildtype.seurat.dir/begin.rds
knockout.seurat.dir/begin.rds
aggregated.seurat.dir/begin.rds

The supplied object must contain an RNA assay with populated "data" and "scale.data" slots for all genes (i.e. you need to run NormlizeData and ScaleData on the RNA assay).

The seurat "JackStraw" and "ScoreJackStraw" functions must have run on the reduced dimensions (e.g. pca) of the default assay of the saved object.

The default assay of the saved object will be used for cell-level analyses such as cluster discovery, computation of tSNE/umap coordinates and pseudotime. Hence, if, for example, integration has been performed, "integrated" should be set as the default assay. For gene level analyses the pipeline will always use the RNA assay regardless of the default assay.

(Optional - velocity) Starting from aggregated dropEst output matrix.

Typically involves linking "dropEst-datasets.dir/sample.layers" subfolders from the
pipeline_cellranger.py run.

Similar to (A), a "data.velocity.dir" folder has to be created with
subfolders of the different conditions. The folder names must end
with ".dir" and folder structure should correspond to (A).


Dependencies
------------

This pipeline requires:

* cgat-core: https://github.com/cgat-developers/cgat-core
* cellranger: https://support.10xgenomics.com/single-cell-gene-expression/
* picard tools (optional): https://broadinstitute.github.io/picard/
* R & various packages.
* Latex.


Pipeline output
===============

For each sample and each combination of paramters the following is generated
in the "report.dir" subfoler:

* A pdf summary report
* A pdf gene expression report (arbitrary sets of genes can be specified)
* An excel table of cluster marker genes
* An excel table of cluster-enriched genesets
* Optionally an excel table of genes differentially expressed within cluster
* Optionally an excel table of genesets enriched in amongst genes
differentially expressed within-cluster

Intermediate results files are also retained in the per-sample directories.

"""

from ruffus import *
from pathlib import Path
import sys
import os
import re
import shutil
import glob
import sqlite3
import numpy as np
import pandas as pd
import yaml
from scipy.stats.mstats import gmean
import cgatcore.experiment as E
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

# -------------------------- < parse parameters > --------------------------- #

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline.yml" % os.path.splitext(__file__)[0],
     "../pipeline.yml",
     "pipeline.yml"])

# set the location of the tenx code directory
if "tenx_dir" not in PARAMS.keys():
    PARAMS["tenx_dir"] = Path(__file__).parents[1]
else:
    raise ValueError("Could not set the location of the tenx code directory")


# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))


# ########################################################################### #
# ############ construct one seurat object per input matrix ################# #
# ########################################################################### #

# QC, normalisation and dimension reduction are performed on the object.

@transform("data.dir/*.dir",
           regex(r".*/(.*).dir"),
           r"\1.seurat.dir/begin.rds")
def qc(infile, outfile):
    '''Setup the Seurat object and save it in RDS format.

       The Rscript "seurat_begin.R" reads in the raw data, performs
       QC filtering, removal of unwanted varation, identification of
       variable genes and PCA-based dimension reduction.
    '''

    outdir = outfile.split("/")[0]

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    sample_name = infile.split("/")[-1].split(".")[0]

    job_memory = PARAMS["resources_memory_standard"]
    job_threads = PARAMS["resources_numcores"]

    log_file = outfile.replace(".rds", ".log")

    # populate an options dictionary with relevant parameters
    param_keys = ("normalization", "vargenes", "regress", "qc",
                  "cellcycle")

    options = {k: v for k, v in PARAMS.items()
               if k.split("_")[0] in param_keys}

    # add task specific options

    options["tenxdir"] = infile
    options["project"] = sample_name
    options["outdir"] = outdir
    options["metadata"] = os.path.join(infile, "metadata.tsv.gz")

    # params for subsetting
    if PARAMS["subset_whitelist"]:

        cells_to_use = PARAMS["subset_" + sample_name]

        if cells_to_use == "use.all":
            options["subset_white_list"] = "NULL"
        elif not os.path.exists(cells_to_use):
                raise ValueError("white list file not found")
        else:
            options["subset_white_list"] = cells_to_use

    options["subset_factor"] = PARAMS["subset_factor"]
    options["subset_level"] = PARAMS["subset_level"]
    options["subset_black_list"] = PARAMS["subset_blacklist"]

    # Turn Python boolean into R logical
    downsamplecells = str(PARAMS["qc_downsamplecells"]).upper()

    options["downsamplecells"] = downsamplecells

    # save the parameters
    task_yaml_file = os.path.abspath(os.path.join(outdir, "seurat_quality_assessment.yml"))
    with open(task_yaml_file, 'w') as yaml_file:
        yaml.dump(options, yaml_file)

    output_dir = os.path.abspath(outdir)
    fig_path =  os.path.join(output_dir, "fig.dir/")
    knit_root_dir = os.getcwd()

    statement = '''Rscript -e "rmarkdown::render('%(tenx_dir)s/Rmd/seurat_quality_assessment.R',
                   output_dir = '%(output_dir)s',
                   intermediates_dir = '%(output_dir)s',
                   knit_root_dir= '%(knit_root_dir)s',
                   params=list('task_yml' = '%(task_yaml_file)s', 'fig_path' = '%(fig_path)s'))"
                   &> %(log_file)s
                '''

    P.run(statement)



# ########################################################################### #
# ##################### full target: to run all tasks ####################### #
# ########################################################################### #

@follows(qc)
def full():
    pass


# ------------------- < ***** end of pipeline **** > ------------------------ #

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
